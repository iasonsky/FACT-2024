{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Of42Ktq5Qr6"
      },
      "outputs": [],
      "source": [
        "!pip install kmedoids\n",
        "!pip install gdown\n",
        "!pip install python-mnist\n",
        "!pip install pulp\n",
        "!pip install scikit-learn==0.22.2 --upgrade\n",
        "!pip install zoopt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "MwHtZKwz5q20"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "c:\\Users\\iason\\Dev\\CFC\\Fair-Clustering-Codebase\n"
          ]
        }
      ],
      "source": [
        "%cd Fair-Clustering-Codebase/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "mts-RZ9kTT6w"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Volume in drive C is Windows\n",
            " Volume Serial Number is C0DD-1089\n",
            "\n",
            " Directory of c:\\Users\\iason\\Dev\\CFC\\Fair-Clustering-Codebase\n",
            "\n",
            "10/01/2024  04:11 ��    <DIR>          .\n",
            "10/01/2024  04:11 ��    <DIR>          ..\n",
            "10/01/2024  04:11 ��    <DIR>          Consensus-Fair-Clustering\n",
            "10/01/2024  04:11 ��    <DIR>          fair_clustering\n",
            "10/01/2024  04:11 ��            28.880 s_DIGITS.npy\n",
            "10/01/2024  04:11 ��               288 s_TOY.npy\n",
            "10/01/2024  04:11 ��             8.752 U_idx_DIGITS.npy\n",
            "10/01/2024  04:11 ��             9.248 U_idx_MNIST_USPS.npy\n",
            "10/01/2024  04:11 ��             1.160 U_idx_Office-31.npy\n",
            "10/01/2024  04:11 ��               176 U_idx_TOY.npy\n",
            "10/01/2024  04:11 ��             5.920 U_idx_Yale.npy\n",
            "10/01/2024  04:11 ��            20.256 V_idx_DIGITS.npy\n",
            "10/01/2024  04:11 ��            21.408 V_idx_MNIST_USPS.npy\n",
            "10/01/2024  04:11 ��             9.440 V_idx_Office-31.npy\n",
            "10/01/2024  04:11 ��               240 V_idx_TOY.npy\n",
            "10/01/2024  04:11 ��            13.648 V_idx_Yale.npy\n",
            "10/01/2024  04:11 ��         1.840.256 X_DIGITS.npy\n",
            "10/01/2024  04:11 ��               928 X_TOY.npy\n",
            "10/01/2024  04:11 ��            28.880 y_DIGITS.npy\n",
            "10/01/2024  04:11 ��               528 y_TOY.npy\n",
            "              16 File(s)      1.990.008 bytes\n",
            "               4 Dir(s)  60.095.508.480 bytes free\n"
          ]
        }
      ],
      "source": [
        "!dir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "SfGHMVvV51A9"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import numpy as np\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics.pairwise import euclidean_distances\n",
        "import pandas as pd\n",
        "import random\n",
        "import kmedoids\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.random_projection import SparseRandomProjection\n",
        "from zoopt import Dimension, ValueType, Objective, Parameter, Opt, ExpOpt\n",
        "# import seaborn as sns\n",
        "\n",
        "import warnings \n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from fair_clustering.eval.functions import * #[TO-DO] Write base class and derive metrics from it, temporary eval code\n",
        "\n",
        "from fair_clustering.dataset import ExtendedYaleB, Office31, MNISTUSPS\n",
        "from fair_clustering.algorithm import FairSpectral, FairKCenter, FairletDecomposition, ScalableFairletDecomposition\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xgp3-g3RYGf7"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "PMbLij2c7-Wl"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Download domain_adaptation_features_20110616.tar.gz from https://drive.google.com/u/0/uc?id=0B4IapRTv9pJ1WTVSd2FIcW4wRTA&export=download\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/u/0/uc?id=0B4IapRTv9pJ1WTVSd2FIcW4wRTA&export=download\n",
            "To: c:\\Users\\iason\\.conda\\envs\\fact2024\\python37.zip\\fair_clustering\\raw_data\\office31\\domain_adaptation_features_20110616.tar.gz\n",
            "100%|██████████| 1.44M/1.44M [00:00<00:00, 29.3MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Download office31_resnet50.zip from https://wjdcloud.blob.core.windows.net/dataset/office31_resnet50.zip\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://wjdcloud.blob.core.windows.net/dataset/office31_resnet50.zip\n",
            "To: c:\\Users\\iason\\.conda\\envs\\fact2024\\python37.zip\\fair_clustering\\raw_data\\office31\\office31_resnet50.zip\n",
            "100%|██████████| 227M/227M [00:53<00:00, 4.24MB/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1293, 2048) (1293,) (1293,)\n"
          ]
        }
      ],
      "source": [
        "# Set parameters related to dataset and get dataset\n",
        "\n",
        "name = 'Office-31' #Choose between Office-31, MNIST_USPS, Yale, or DIGITS\n",
        "\n",
        "if name == 'Office-31':\n",
        "  dataset = Office31(exclude_domain='amazon', use_feature=True)\n",
        "  X, y, s = dataset.data\n",
        "elif name == 'MNIST_USPS':\n",
        "  dataset = MNISTUSPS(download=True)\n",
        "  X, y, s = dataset.data\n",
        "elif name == 'Yale':\n",
        "  dataset = ExtendedYaleB(download=True, resize=True)\n",
        "  X, y, s = dataset.data\n",
        "elif name == 'DIGITS':\n",
        "  X, y, s = np.load('X_' + name + '.npy'), np.load('y_' + name + '.npy'), np.load('s_' + name + '.npy')\n",
        "\n",
        "print(X.shape, y.shape, s.shape)\n",
        "\n",
        "cl_algo = 'SFD' #Choose between FSC or SFD. For KFC run notebook locally (KFC is not available in Colab due to CPLEX being incompatible with Colab)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_aXpU_Zq7sFm"
      },
      "outputs": [],
      "source": [
        "# Fairness Attack"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "RAd8O8tYbekD"
      },
      "outputs": [],
      "source": [
        "def attack_balance(solution):\n",
        "  X_copy, s_copy = X.copy(), s.copy()\n",
        "  flipped_labels = solution.get_x()\n",
        "  i = 0\n",
        "  for idx in U_idx:\n",
        "    s_copy[idx] = flipped_labels[i]\n",
        "    i += 1\n",
        "\n",
        "  if cl_algo == 'FSC':\n",
        "    if name == 'MNIST_USPS':\n",
        "      metr_str = 'manhattan'\n",
        "    else:\n",
        "      metr_str = 'euclidean'\n",
        "    fair_clustering_algo = FairSpectral(n_clusters=n_clusters, num_neighbors=3, metric_str=metr_str, random_state=random_state)\n",
        "  if cl_algo =='SFD':\n",
        "    if name == 'DIGITS':      \n",
        "      fair_clustering_algo = ScalableFairletDecomposition(n_clusters=n_clusters, alpha=5, beta=1, random_state=random_state) \n",
        "    else:\n",
        "      fair_clustering_algo = ScalableFairletDecomposition(n_clusters=n_clusters, alpha=5, beta=2, random_state=random_state) \n",
        "  \n",
        "  fair_clustering_algo.fit(X_copy, s_copy)\n",
        "  labels_sfd = fair_clustering_algo.labels_\n",
        "\n",
        "  s_eval = []\n",
        "  X_eval = []\n",
        "  labels_sfd_eval = []\n",
        "  for idx in V_idx:\n",
        "    s_eval.append(s_copy[idx])\n",
        "    X_eval.append(X_copy[idx])\n",
        "    labels_sfd_eval.append(labels_sfd[idx])\n",
        "  s_eval = np.array(s_eval)\n",
        "  X_eval = np.array(X_eval)\n",
        "  labels_sfd_eval = np.array(labels_sfd_eval)\n",
        "\n",
        "  bal = balance(labels_sfd_eval, X_eval, s_eval)\n",
        "\n",
        "  return bal\n",
        "\n",
        "\n",
        "def attack_entropy(solution):\n",
        "  X_copy, s_copy = X.copy(), s.copy()\n",
        "  flipped_labels = solution.get_x()\n",
        "  i = 0\n",
        "  for idx in U_idx:\n",
        "    s_copy[idx] = flipped_labels[i]\n",
        "    i += 1\n",
        "\n",
        "  if cl_algo == 'FSC':\n",
        "    if name == 'MNIST_USPS':\n",
        "      metr_str = 'manhattan'\n",
        "    else:\n",
        "      metr_str = 'euclidean'\n",
        "    fair_clustering_algo = FairSpectral(n_clusters=n_clusters, num_neighbors=3, metric_str=metr_str, random_state=random_state)\n",
        "  if cl_algo =='SFD':\n",
        "    if name == 'DIGITS':      \n",
        "      fair_clustering_algo = ScalableFairletDecomposition(n_clusters=n_clusters, alpha=5, beta=1, random_state=random_state) \n",
        "    else:\n",
        "      fair_clustering_algo = ScalableFairletDecomposition(n_clusters=n_clusters, alpha=5, beta=2, random_state=random_state) \n",
        "  \n",
        "  fair_clustering_algo.fit(X_copy, s_copy)\n",
        "  labels_sfd = fair_clustering_algo.labels_\n",
        "\n",
        "  s_eval = []\n",
        "  X_eval = []\n",
        "  labels_sfd_eval = []\n",
        "  for idx in V_idx:\n",
        "    s_eval.append(s_copy[idx])\n",
        "    X_eval.append(X_copy[idx])\n",
        "    labels_sfd_eval.append(labels_sfd[idx])\n",
        "  s_eval = np.array(s_eval)\n",
        "  X_eval = np.array(X_eval)\n",
        "  labels_sfd_eval = np.array(labels_sfd_eval)\n",
        "\n",
        "  ent = entropy(labels_sfd_eval, s_eval)\n",
        "\n",
        "  return ent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "D6wxONfygXIh"
      },
      "outputs": [],
      "source": [
        "def process_solution(sol):\n",
        "  X_copy, s_copy, y_copy = X.copy(), s.copy(), y.copy()\n",
        "  flipped_labels = sol.get_x()\n",
        "  i = 0\n",
        "  for idx in U_idx:\n",
        "    s_copy[idx] = flipped_labels[i]\n",
        "    i += 1\n",
        "\n",
        "  if cl_algo == 'FSC':\n",
        "    if name == 'MNIST_USPS':\n",
        "      metr_str = 'manhattan'\n",
        "    else:\n",
        "      metr_str = 'euclidean'\n",
        "    fair_clustering_algo = FairSpectral(n_clusters=n_clusters, num_neighbors=3, metric_str=metr_str, random_state=random_state)\n",
        "  if cl_algo =='SFD':\n",
        "    if name == 'DIGITS':      \n",
        "      fair_clustering_algo = ScalableFairletDecomposition(n_clusters=n_clusters, alpha=5, beta=1, random_state=random_state)\n",
        "    else:\n",
        "      fair_clustering_algo = ScalableFairletDecomposition(n_clusters=n_clusters, alpha=5, beta=2, random_state=random_state) \n",
        "  \n",
        "  fair_clustering_algo.fit(X_copy, s_copy)\n",
        "  labels_sfd = fair_clustering_algo.labels_\n",
        "\n",
        "  s_eval = []\n",
        "  X_eval = []\n",
        "  labels_sfd_eval = []\n",
        "  y_eval = []\n",
        "  for idx in V_idx:\n",
        "    s_eval.append(s_copy[idx])\n",
        "    X_eval.append(X_copy[idx])\n",
        "    labels_sfd_eval.append(labels_sfd[idx])\n",
        "    y_eval.append(y_copy[idx])\n",
        "  s_eval = np.array(s_eval)\n",
        "  X_eval = np.array(X_eval)\n",
        "  labels_sfd_eval = np.array(labels_sfd_eval)\n",
        "  y_eval = np.array(y_eval)\n",
        "\n",
        "  bal = balance(labels_sfd_eval, X_eval, s_eval)\n",
        "  ent = entropy(labels_sfd_eval, s_eval)\n",
        "  accuracy = acc(y_eval, labels_sfd_eval)\n",
        "  nmi_score = nmi(y_eval, labels_sfd_eval)\n",
        "\n",
        "  return (bal, ent, accuracy, nmi_score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "vs6CcYUsMjLW"
      },
      "outputs": [],
      "source": [
        "def conduct_random_attack(size_sol):\n",
        "  X_copy, s_copy, y_copy = X.copy(), s.copy(), y.copy()\n",
        "  random.seed(None)\n",
        "  flipped_labels = [random.randint(0,1) for _ in range(size_sol)]\n",
        "  i = 0\n",
        "  for idx in U_idx:\n",
        "    s_copy[idx] = flipped_labels[i]\n",
        "    i += 1\n",
        "\n",
        "  if cl_algo == 'FSC':\n",
        "    if name == 'MNIST_USPS':\n",
        "      metr_str = 'manhattan'\n",
        "    else:\n",
        "      metr_str = 'euclidean'\n",
        "    fair_clustering_algo = FairSpectral(n_clusters=n_clusters, num_neighbors=3, metric_str=metr_str, random_state=random_state)\n",
        "  if cl_algo =='SFD':\n",
        "    if name == 'DIGITS':      \n",
        "      fair_clustering_algo = ScalableFairletDecomposition(n_clusters=n_clusters, alpha=5, beta=1, random_state=random_state) #5,2\n",
        "    else:\n",
        "      fair_clustering_algo = ScalableFairletDecomposition(n_clusters=n_clusters, alpha=5, beta=2, random_state=random_state) #5,2\n",
        "\n",
        "  fair_clustering_algo.fit(X_copy, s_copy)\n",
        "  labels_sfd = fair_clustering_algo.labels_\n",
        "\n",
        "  s_eval = []\n",
        "  X_eval = []\n",
        "  labels_sfd_eval = []\n",
        "  y_eval = []\n",
        "  for idx in V_idx:\n",
        "    s_eval.append(s_copy[idx])\n",
        "    X_eval.append(X_copy[idx])\n",
        "    labels_sfd_eval.append(labels_sfd[idx])\n",
        "    y_eval.append(y_copy[idx])\n",
        "  s_eval = np.array(s_eval)\n",
        "  X_eval = np.array(X_eval)\n",
        "  labels_sfd_eval = np.array(labels_sfd_eval)\n",
        "  y_eval = np.array(y_eval)\n",
        "\n",
        "  bal = balance(labels_sfd_eval, X_eval, s_eval)\n",
        "  ent = entropy(labels_sfd_eval, s_eval)\n",
        "  accuracy = acc(y_eval, labels_sfd_eval)\n",
        "  nmi_score = nmi(y_eval, labels_sfd_eval)\n",
        "\n",
        "  return (bal, ent, accuracy, nmi_score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Uel612jHeVs1"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'np' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_18412\\606892254.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mn_clusters\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"# of clusters -> \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_clusters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mseeds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m150\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4200\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m424242\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1947\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m355\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m256\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m7500\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m99999\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m18\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mn_trials\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseeds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "n_clusters = len(np.unique(y))\n",
        "print(\"# of clusters -> \" + str(n_clusters))\n",
        "seeds = [150, 1, 4200, 424242, 1947, 355, 256, 7500, 99999, 18]\n",
        "n_trials = len(seeds)\n",
        "\n",
        "U_idx_full, V_idx_full = np.load('U_idx_' + name + '.npy').tolist(), np.load('V_idx_' + name + '.npy').tolist()\n",
        "\n",
        "pre_attack_res = {\n",
        "    0 : {'BALANCE': [], 'ENTROPY': [], 'ACC': [], 'NMI': []},\n",
        "    1 : {'BALANCE': [], 'ENTROPY': [], 'ACC': [], 'NMI': []},\n",
        "    2 : {'BALANCE': [], 'ENTROPY': [], 'ACC': [], 'NMI': []},\n",
        "    3 : {'BALANCE': [], 'ENTROPY': [], 'ACC': [], 'NMI': []},\n",
        "    4 : {'BALANCE': [], 'ENTROPY': [], 'ACC': [], 'NMI': []},\n",
        "    5 : {'BALANCE': [], 'ENTROPY': [], 'ACC': [], 'NMI': []},\n",
        "    6 : {'BALANCE': [], 'ENTROPY': [], 'ACC': [], 'NMI': []},\n",
        "    7 : {'BALANCE': [], 'ENTROPY': [], 'ACC': [], 'NMI': []},\n",
        "}\n",
        "\n",
        "post_attack_res = {\n",
        "    0 : {'BALANCE': [], 'ENTROPY': [], 'ACC': [], 'NMI': []},\n",
        "    1 : {'BALANCE': [], 'ENTROPY': [], 'ACC': [], 'NMI': []},\n",
        "    2 : {'BALANCE': [], 'ENTROPY': [], 'ACC': [], 'NMI': []},\n",
        "    3 : {'BALANCE': [], 'ENTROPY': [], 'ACC': [], 'NMI': []},\n",
        "    4 : {'BALANCE': [], 'ENTROPY': [], 'ACC': [], 'NMI': []},\n",
        "    5 : {'BALANCE': [], 'ENTROPY': [], 'ACC': [], 'NMI': []},\n",
        "    6 : {'BALANCE': [], 'ENTROPY': [], 'ACC': [], 'NMI': []},\n",
        "    7 : {'BALANCE': [], 'ENTROPY': [], 'ACC': [], 'NMI': []},\n",
        "}\n",
        "\n",
        "random_attack_res = {\n",
        "    0 : {'BALANCE': [], 'ENTROPY': [], 'ACC': [], 'NMI': []},\n",
        "    1 : {'BALANCE': [], 'ENTROPY': [], 'ACC': [], 'NMI': []},\n",
        "    2 : {'BALANCE': [], 'ENTROPY': [], 'ACC': [], 'NMI': []},\n",
        "    3 : {'BALANCE': [], 'ENTROPY': [], 'ACC': [], 'NMI': []},\n",
        "    4 : {'BALANCE': [], 'ENTROPY': [], 'ACC': [], 'NMI': []},\n",
        "    5 : {'BALANCE': [], 'ENTROPY': [], 'ACC': [], 'NMI': []},\n",
        "    6 : {'BALANCE': [], 'ENTROPY': [], 'ACC': [], 'NMI': []},\n",
        "    7 : {'BALANCE': [], 'ENTROPY': [], 'ACC': [], 'NMI': []},\n",
        "}\n",
        "\n",
        "for percent, j in enumerate([int(0.125*len(U_idx_full)), int(0.25*len(U_idx_full)), int(0.375*len(U_idx_full)), int(0.5*len(U_idx_full)), int(0.625*len(U_idx_full)), int(0.75*len(U_idx_full)), int(0.875*len(U_idx_full)), int(len(U_idx_full))]):\n",
        "  \n",
        "  U_idx = U_idx_full[:j]\n",
        "  V_idx = V_idx_full\n",
        "\n",
        "  for trial_idx in range(n_trials):\n",
        "    random_state = seeds[trial_idx]\n",
        "    \n",
        "    if cl_algo == 'FSC':\n",
        "      if name == 'MNIST_USPS':\n",
        "        metric_string = 'manhattan'\n",
        "      else:\n",
        "        metric_string = 'euclidean'\n",
        "      fair_algo = FairSpectral(n_clusters=n_clusters, num_neighbors=3, metric_str = metric_string, random_state=random_state)\n",
        "      fair_algo.fit(X, s)\n",
        "      labels = fair_algo.labels_\n",
        "    if cl_algo =='SFD':\n",
        "      if name == 'DIGITS':      \n",
        "        fair_algo = ScalableFairletDecomposition(n_clusters=n_clusters, alpha=5, beta=1, random_state=random_state) #5,2\n",
        "      else:\n",
        "        fair_algo = ScalableFairletDecomposition(n_clusters=n_clusters, alpha=5, beta=2, random_state=random_state) #5,2\n",
        "      fair_algo.fit(X, s)\n",
        "      labels = fair_algo.labels_\n",
        "    \n",
        "\n",
        "    s_test = []\n",
        "    X_test = []\n",
        "    labels_test = []\n",
        "    y_test = []\n",
        "    for idx in V_idx:\n",
        "      s_test.append(s[idx])\n",
        "      X_test.append(X[idx])\n",
        "      labels_test.append(labels[idx])\n",
        "      y_test.append(y[idx])\n",
        "    s_test = np.array(s_test)\n",
        "    X_test = np.array(X_test)\n",
        "    labels_test = np.array(labels_test)\n",
        "    y_test = np.array(y_test)\n",
        "\n",
        "    \n",
        "    pre_attack_res[percent]['BALANCE'].append(balance(labels_test, X_test, s_test))\n",
        "    pre_attack_res[percent]['ENTROPY'].append(entropy(labels_test, s_test))\n",
        "    pre_attack_res[percent]['ACC'].append(acc(y_test, labels_test))\n",
        "    pre_attack_res[percent]['NMI'].append(nmi(y_test, labels_test))\n",
        "    \n",
        "    dim_size = len(U_idx)\n",
        "    dim = Dimension(dim_size, [[0, 1]]*dim_size, [False]*dim_size)\n",
        "\n",
        "    if name == 'Office-31': #Only attack_balance\n",
        "      obj = Objective(attack_balance, dim)\n",
        "    elif name == 'MNIST_USPS' or name == 'DIGITS':\n",
        "      if cl_algo == 'SFD':\n",
        "        obj = Objective(attack_balance, dim)\n",
        "      elif cl_algo == 'FSC':\n",
        "        obj = Objective(attack_entropy, dim)\n",
        "    elif name == 'Yale': #Only attack_entropy\n",
        "      obj = Objective(attack_entropy, dim)\n",
        "    \n",
        "    solution = Opt.min(obj, Parameter(budget=10)) # 10 for FSC for MNIST_USPS and 50 for SFD for MNIST_USPS || 20 for FSC for Office-31 and 20 for SFD for Office-31 || 10 for FSC for Yale and 20 for SFD for Yale || 15 for FSC for DIGITS and 25 for SFD for DIGITS\n",
        "\n",
        "    \n",
        "    pa_bal, pa_ent, pa_acc, pa_nmi = process_solution(solution)\n",
        "    post_attack_res[percent]['BALANCE'].append(pa_bal)\n",
        "    post_attack_res[percent]['ENTROPY'].append(pa_ent)\n",
        "    post_attack_res[percent]['ACC'].append(pa_acc)\n",
        "    post_attack_res[percent]['NMI'].append(pa_nmi)\n",
        "\n",
        "    r_bal, r_ent, r_acc, r_nmi = conduct_random_attack(dim_size)\n",
        "    random_attack_res[percent]['BALANCE'].append(r_bal)\n",
        "    random_attack_res[percent]['ENTROPY'].append(r_ent)\n",
        "    random_attack_res[percent]['ACC'].append(r_acc)\n",
        "    random_attack_res[percent]['NMI'].append(r_nmi)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CJmvA3LPbLMX"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
